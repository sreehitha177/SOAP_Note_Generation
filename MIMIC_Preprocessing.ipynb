{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0w9l7J57E1N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI, RateLimitError, BadRequestError, APIError\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
        "import sys\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONFIGURATION\n",
        "# ==========================================\n",
        "INPUT_CSV = \"NOTEEVENTS.csv\"\n",
        "OUTPUT_FILE = \"mimic_dialogue_soap.jsonl\"\n",
        "CHECKPOINT_FILE = \"progress.checkpoint\"\n",
        "\n",
        "MAX_SAMPLES = 100   # set None for full run\n",
        "CHUNK_SIZE = 1000\n",
        "\n",
        "TARGET_CATEGORIES = [\"Progress Note\", \"Discharge summary\"]\n",
        "\n",
        "EXTRACTOR_MODEL = \"gpt-4.1-mini\"\n",
        "SIMULATOR_MODEL = \"gpt-4o-mini\"\n",
        "\n",
        "# Retry configuration\n",
        "MAX_SOAP_RETRIES = 3\n",
        "MAX_DIALOGUE_RETRIES = 3\n",
        "\n",
        "# ==========================================\n",
        "# 2. CLIENT SETUP\n",
        "# ==========================================\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# ==========================================\n",
        "# 3. PROMPTS\n",
        "# ==========================================\n",
        "SYSTEM_PROMPT_EXTRACTOR = \"\"\"\n",
        "You are an expert Clinical Documentation Improvement (CDI) specialist.\n",
        "\n",
        "Extract factual clinical information from the note into SOAP format.\n",
        "\n",
        "Return STRICT JSON with exactly these 4 keys (no others):\n",
        "- Subjective\n",
        "- Objective\n",
        "- Assessment\n",
        "- Plan\n",
        "\n",
        "Rules:\n",
        "- Do NOT summarize or infer beyond the text\n",
        "- Copy facts verbatim where possible\n",
        "- If a section is missing, return \"Not documented\"\n",
        "- Preserve medical abbreviations and terminology\n",
        "- Include vital signs and lab values with units\n",
        "- Each value must be a string (not array or object)\n",
        "\"\"\"\n",
        "\n",
        "SYSTEM_PROMPT_SIMULATOR = \"\"\"\n",
        "You are generating a realistic doctor‚Äìpatient conversation for medical training.\n",
        "\n",
        "Rules:\n",
        "1. Patient describes symptoms from Subjective section\n",
        "2. Doctor asks clarifying questions based on Objective findings\n",
        "3. Doctor explains Assessment and Plan at the end\n",
        "4. Use 6-12 conversation turns total\n",
        "5. EVERY line must start with exactly \"Doctor:\" or \"Patient:\" followed by a space\n",
        "6. Make dialogue natural with pauses, acknowledgments\n",
        "7. End with doctor summarizing next steps clearly\n",
        "\n",
        "Example format:\n",
        "Doctor: Good morning, how are you feeling today?\n",
        "Patient: I've been having chest pain since yesterday.\n",
        "Doctor: Can you describe the pain for me?\n",
        "... (more turns)\n",
        "\"\"\"\n",
        "\n",
        "# ==========================================\n",
        "# 4. HELPER FUNCTIONS\n",
        "# ==========================================\n",
        "def clean_clinical_text(text):\n",
        "    \"\"\"Clean and sanitize clinical text.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Remove excessive whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # Remove common MIMIC redaction patterns\n",
        "    text = re.sub(r'\\[\\*\\*.*?\\*\\*\\]', '[REDACTED]', text)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "def validate_soap_structure(soap_dict):\n",
        "    \"\"\"Validate SOAP JSON structure and content.\"\"\"\n",
        "    if not isinstance(soap_dict, dict):\n",
        "        return False, \"Not a dictionary\"\n",
        "\n",
        "    # Check for required keys (case-insensitive)\n",
        "    required_keys = {\"subjective\", \"objective\", \"assessment\", \"plan\"}\n",
        "    soap_keys = {k.lower() for k in soap_dict.keys()}\n",
        "\n",
        "    missing_keys = required_keys - soap_keys\n",
        "    if missing_keys:\n",
        "        return False, f\"Missing keys: {missing_keys}\"\n",
        "\n",
        "    # Check each value is a non-empty string\n",
        "    key_map = {k.lower(): k for k in soap_dict.keys()}\n",
        "    empty_patterns = [\"\", \"n/a\", \"none\", \"not documented\", \"not available\", \"na\", \"[]\", \"{}\"]\n",
        "\n",
        "    for req_key in required_keys:\n",
        "        original_key = key_map[req_key]\n",
        "        value = soap_dict[original_key]\n",
        "\n",
        "        # Must be string\n",
        "        if not isinstance(value, str):\n",
        "            return False, f\"{original_key} is not a string\"\n",
        "\n",
        "        value_clean = value.strip().lower()\n",
        "        if value_clean in empty_patterns:\n",
        "            return False, f\"{original_key} is empty or placeholder\"\n",
        "\n",
        "    # Check total content length\n",
        "    total_length = sum(len(str(soap_dict[key_map[k]])) for k in required_keys)\n",
        "    if total_length < 200:\n",
        "        return False, f\"Insufficient content length: {total_length}\"\n",
        "\n",
        "    return True, \"Valid\"\n",
        "\n",
        "def validate_dialogue_structure(dialogue_text):\n",
        "    \"\"\"Validate dialogue format and structure.\"\"\"\n",
        "    if not dialogue_text or not isinstance(dialogue_text, str):\n",
        "        return False, \"No dialogue text\"\n",
        "\n",
        "    lines = dialogue_text.strip().split('\\n')\n",
        "    if len(lines) < 4:  # Minimum 2 turns each\n",
        "        return False, f\"Too few lines: {len(lines)}\"\n",
        "\n",
        "    doctor_count = 0\n",
        "    patient_count = 0\n",
        "    malformed_lines = []\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        if line.startswith(\"Doctor:\"):\n",
        "            doctor_count += 1\n",
        "            # Check there's content after \"Doctor:\"\n",
        "            if len(line) <= len(\"Doctor:\"):\n",
        "                malformed_lines.append(f\"Line {i}: Empty doctor line\")\n",
        "        elif line.startswith(\"Patient:\"):\n",
        "            patient_count += 1\n",
        "            if len(line) <= len(\"Patient:\"):\n",
        "                malformed_lines.append(f\"Line {i}: Empty patient line\")\n",
        "        else:\n",
        "            malformed_lines.append(f\"Line {i}: Doesn't start with Doctor:/Patient:\")\n",
        "\n",
        "    if doctor_count < 2:\n",
        "        return False, f\"Insufficient doctor turns: {doctor_count}\"\n",
        "    if patient_count < 2:\n",
        "        return False, f\"Insufficient patient turns: {patient_count}\"\n",
        "    if malformed_lines:\n",
        "        return False, f\"Malformed lines: {malformed_lines[:3]}\"\n",
        "\n",
        "    # Check dialogue has reasonable length\n",
        "    if len(dialogue_text) < 150:\n",
        "        return False, f\"Dialogue too short: {len(dialogue_text)} chars\"\n",
        "\n",
        "    return True, f\"Valid: {doctor_count} doctor, {patient_count} patient turns\"\n",
        "\n",
        "def extract_relevant_text_chunk(text, max_chars=4000):\n",
        "    \"\"\"Extract middle portion of text to avoid headers/footers.\"\"\"\n",
        "    if len(text) <= max_chars:\n",
        "        return text\n",
        "\n",
        "    # Take middle section, avoiding beginning (headers) and end (signatures)\n",
        "    start_idx = max(0, len(text) // 2 - max_chars // 2)\n",
        "    return text[start_idx:start_idx + max_chars]\n",
        "\n",
        "def load_checkpoint():\n",
        "    \"\"\"Load processing checkpoint if exists.\"\"\"\n",
        "    if os.path.exists(CHECKPOINT_FILE):\n",
        "        try:\n",
        "            with open(CHECKPOINT_FILE, \"r\") as f:\n",
        "                return int(f.read().strip())\n",
        "        except:\n",
        "            return 0\n",
        "    return 0\n",
        "\n",
        "def save_checkpoint(processed_count):\n",
        "    \"\"\"Save processing checkpoint.\"\"\"\n",
        "    with open(CHECKPOINT_FILE, \"w\") as f:\n",
        "        f.write(str(processed_count))\n",
        "\n",
        "# ==========================================\n",
        "# 5. LLM HELPERS WITH RETRY & VALIDATION\n",
        "# ==========================================\n",
        "@retry(\n",
        "    stop=stop_after_attempt(5),\n",
        "    wait=wait_exponential(multiplier=1, min=2, max=30),\n",
        "    retry=retry_if_exception_type((RateLimitError, APIError)),\n",
        "    reraise=True\n",
        ")\n",
        "def call_llm_with_retry(system_prompt, user_prompt, model, json_mode=False):\n",
        "    \"\"\"Call LLM with retry for API errors.\"\"\"\n",
        "    try:\n",
        "        response = client.responses.create(\n",
        "            model=model,\n",
        "            input=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            temperature=0.6,\n",
        "            response_format={\"type\": \"json_object\"} if json_mode else None,\n",
        "            max_tokens=2000 if json_mode else 1500\n",
        "        )\n",
        "        return response.output_text\n",
        "    except BadRequestError as e:\n",
        "        # Don't retry on bad requests (content filter, invalid input)\n",
        "        print(f\"‚ùå Bad request (won't retry): {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è API error: {e}\")\n",
        "        raise  # Let tenacity handle retryable errors\n",
        "\n",
        "def extract_soap_from_note(note_text, max_retries=MAX_SOAP_RETRIES):\n",
        "    \"\"\"Extract SOAP with validation and retry on malformed responses.\"\"\"\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            # Call LLM\n",
        "            soap_str = call_llm_with_retry(\n",
        "                SYSTEM_PROMPT_EXTRACTOR,\n",
        "                f\"Extract SOAP from this clinical note:\\n\\n{note_text}\",\n",
        "                model=EXTRACTOR_MODEL,\n",
        "                json_mode=True\n",
        "            )\n",
        "\n",
        "            if not soap_str:\n",
        "                if attempt < max_retries - 1:\n",
        "                    print(f\"‚ö†Ô∏è Empty SOAP response, retry {attempt + 1}/{max_retries}\")\n",
        "                    continue\n",
        "                return None, \"Empty response\"\n",
        "\n",
        "            # Parse JSON\n",
        "            soap = json.loads(soap_str)\n",
        "\n",
        "            # Validate structure\n",
        "            is_valid, message = validate_soap_structure(soap)\n",
        "\n",
        "            if is_valid:\n",
        "                # Standardize keys\n",
        "                key_map = {k.lower(): k for k in soap.keys()}\n",
        "                soap_standard = {\n",
        "                    \"Subjective\": soap[key_map[\"subjective\"]],\n",
        "                    \"Objective\": soap[key_map[\"objective\"]],\n",
        "                    \"Assessment\": soap[key_map[\"assessment\"]],\n",
        "                    \"Plan\": soap[key_map[\"plan\"]]\n",
        "                }\n",
        "                return soap_standard, None\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Invalid SOAP (attempt {attempt + 1}/{max_retries}): {message}\")\n",
        "\n",
        "                # If last attempt, try to fix common issues\n",
        "                if attempt == max_retries - 1:\n",
        "                    # Attempt to salvage by checking for any usable data\n",
        "                    key_map = {k.lower(): k for k in soap.keys()}\n",
        "                    salvageable_keys = {\"subjective\", \"objective\", \"assessment\", \"plan\"} & set(key_map.keys())\n",
        "                    if len(salvageable_keys) >= 2:\n",
        "                        print(f\"‚ö†Ô∏è Salvaging partial SOAP with keys: {salvageable_keys}\")\n",
        "                        soap_standard = {}\n",
        "                        for key in [\"Subjective\", \"Objective\", \"Assessment\", \"Plan\"]:\n",
        "                            if key.lower() in key_map:\n",
        "                                soap_standard[key] = soap[key_map[key.lower()]]\n",
        "                            else:\n",
        "                                soap_standard[key] = \"Not documented\"\n",
        "                        return soap_standard, \"Partially salvaged\"\n",
        "\n",
        "                # Add progressive guidance on retry\n",
        "                guidance = \"\"\n",
        "                if attempt == 1:\n",
        "                    guidance = \" Remember: return JSON with exactly 4 keys: Subjective, Objective, Assessment, Plan.\"\n",
        "                elif attempt == 2:\n",
        "                    guidance = \" Each value must be a non-empty string. No extra keys.\"\n",
        "\n",
        "                if attempt < max_retries - 1:\n",
        "                    # Modify prompt slightly to guide better response\n",
        "                    enhanced_prompt = SYSTEM_PROMPT_EXTRACTOR + guidance\n",
        "                    soap_str = call_llm_with_retry(\n",
        "                        enhanced_prompt,\n",
        "                        f\"Extract SOAP from this clinical note. IMPORTANT: Return JSON with exactly 4 keys (Subjective, Objective, Assessment, Plan). Each value must be a non-empty string.\\n\\n{note_text}\",\n",
        "                        model=EXTRACTOR_MODEL,\n",
        "                        json_mode=True\n",
        "                    )\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"‚ö†Ô∏è JSON decode error (attempt {attempt + 1}/{max_retries}): {e}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(1)\n",
        "                continue\n",
        "            return None, f\"JSON decode error: {e}\"\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Unexpected error in SOAP extraction (attempt {attempt + 1}/{max_retries}): {e}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(2 ** attempt)  # Exponential backoff\n",
        "                continue\n",
        "            return None, f\"Unexpected error: {e}\"\n",
        "\n",
        "    return None, f\"Failed after {max_retries} attempts\"\n",
        "\n",
        "def generate_dialogue_from_soap(soap_dict, max_retries=MAX_DIALOGUE_RETRIES):\n",
        "    \"\"\"Generate dialogue with validation and retry on malformed responses.\"\"\"\n",
        "    soap_json_str = json.dumps(soap_dict, indent=2)\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            # Call LLM\n",
        "            dialogue = call_llm_with_retry(\n",
        "                SYSTEM_PROMPT_SIMULATOR,\n",
        "                f\"Create a doctor-patient dialogue based on these clinical facts:\\n{soap_json_str}\",\n",
        "                model=SIMULATOR_MODEL\n",
        "            )\n",
        "\n",
        "            if not dialogue:\n",
        "                if attempt < max_retries - 1:\n",
        "                    print(f\"‚ö†Ô∏è Empty dialogue response, retry {attempt + 1}/{max_retries}\")\n",
        "                    continue\n",
        "                return None, \"Empty response\"\n",
        "\n",
        "            # Validate dialogue structure\n",
        "            is_valid, message = validate_dialogue_structure(dialogue)\n",
        "\n",
        "            if is_valid:\n",
        "                return dialogue, None\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Invalid dialogue (attempt {attempt + 1}/{max_retries}): {message}\")\n",
        "\n",
        "                # Provide more explicit guidance on retry\n",
        "                guidance = \"\\n\\nIMPORTANT FORMAT: Every line MUST start with exactly 'Doctor:' or 'Patient:' followed by a space. No other prefixes allowed.\"\n",
        "\n",
        "                if attempt < max_retries - 1:\n",
        "                    enhanced_prompt = SYSTEM_PROMPT_SIMULATOR + guidance\n",
        "                    dialogue = call_llm_with_retry(\n",
        "                        enhanced_prompt,\n",
        "                        f\"Create a doctor-patient dialogue based on these clinical facts. CRITICAL: Every line must start with 'Doctor:' or 'Patient:' followed by a space.\\n\\n{soap_json_str}\",\n",
        "                        model=SIMULATOR_MODEL\n",
        "                    )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Unexpected error in dialogue generation (attempt {attempt + 1}/{max_retries}): {e}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(2 ** attempt)\n",
        "                continue\n",
        "\n",
        "    return None, f\"Failed after {max_retries} attempts\"\n",
        "\n",
        "# ==========================================\n",
        "# 6. CORE PIPELINE\n",
        "# ==========================================\n",
        "def process_mimic():\n",
        "    \"\"\"Main processing pipeline.\"\"\"\n",
        "\n",
        "    # Validate input file and columns\n",
        "    if not os.path.exists(INPUT_CSV):\n",
        "        print(f\"‚ùå {INPUT_CSV} not found\")\n",
        "        return None\n",
        "\n",
        "    # Check required columns\n",
        "    try:\n",
        "        df_sample = pd.read_csv(INPUT_CSV, nrows=1)\n",
        "        required_cols = [\"CATEGORY\", \"TEXT\"]\n",
        "        if not all(col in df_sample.columns for col in required_cols):\n",
        "            print(f\"‚ùå Missing required columns. Found: {df_sample.columns.tolist()}\")\n",
        "            print(f\"   Required: {required_cols}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error reading CSV: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Initialize stats\n",
        "    stats = {\n",
        "        \"total_processed\": 0,\n",
        "        \"skipped_short\": 0,\n",
        "        \"soap_fail\": 0,\n",
        "        \"soap_retry_success\": 0,\n",
        "        \"dialogue_fail\": 0,\n",
        "        \"dialogue_retry_success\": 0,\n",
        "        \"saved\": 0,\n",
        "        \"soap_validation_errors\": {},\n",
        "        \"dialogue_validation_errors\": {}\n",
        "    }\n",
        "\n",
        "    # Load checkpoint\n",
        "    checkpoint = load_checkpoint()\n",
        "    if checkpoint > 0:\n",
        "        print(f\"üîÑ Resuming from checkpoint: {checkpoint} samples processed\")\n",
        "\n",
        "    # Process data\n",
        "    try:\n",
        "        with open(OUTPUT_FILE, \"a\" if checkpoint > 0 else \"w\", encoding=\"utf-8\") as fout:\n",
        "            chunk_iterator = pd.read_csv(INPUT_CSV, chunksize=CHUNK_SIZE)\n",
        "\n",
        "            # Skip approximate number of chunks based on checkpoint\n",
        "            # (This is approximate since we don't know exact distribution)\n",
        "            chunks_to_skip = checkpoint // (CHUNK_SIZE // 20)  # Conservative estimate\n",
        "            for _ in range(chunks_to_skip):\n",
        "                next(chunk_iterator, None)\n",
        "\n",
        "            for chunk_idx, chunk in enumerate(chunk_iterator):\n",
        "                print(f\"\\nüìÇ Processing chunk {chunk_idx + 1 + chunks_to_skip}...\")\n",
        "\n",
        "                # Filter by category\n",
        "                df = chunk[chunk[\"CATEGORY\"].isin(TARGET_CATEGORIES)].copy()\n",
        "\n",
        "                if df.empty:\n",
        "                    continue\n",
        "\n",
        "                for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Notes\"):\n",
        "                    # Stop if MAX_SAMPLES reached\n",
        "                    if MAX_SAMPLES and stats[\"saved\"] >= MAX_SAMPLES:\n",
        "                        print(f\"\\n‚úÖ Reached MAX_SAMPLES ({MAX_SAMPLES})\")\n",
        "                        return stats\n",
        "\n",
        "                    # Skip if we haven't reached checkpoint yet\n",
        "                    if stats[\"saved\"] < checkpoint:\n",
        "                        # Just count but don't process\n",
        "                        stats[\"total_processed\"] += 1\n",
        "                        if len(str(row[\"TEXT\"])) < 300:\n",
        "                            stats[\"skipped_short\"] += 1\n",
        "                        continue\n",
        "\n",
        "                    stats[\"total_processed\"] += 1\n",
        "\n",
        "                    # Get and clean text\n",
        "                    raw_text = str(row[\"TEXT\"])\n",
        "                    raw_text = clean_clinical_text(raw_text)\n",
        "\n",
        "                    # Skip short notes\n",
        "                    if len(raw_text) < 300:\n",
        "                        stats[\"skipped_short\"] += 1\n",
        "                        continue\n",
        "\n",
        "                    # Extract relevant portion\n",
        "                    note_chunk = extract_relevant_text_chunk(raw_text, max_chars=4000)\n",
        "\n",
        "                    # ---- STEP A: RAW NOTE ‚Üí SOAP (with retry) ----\n",
        "                    soap, error_msg = extract_soap_from_note(note_chunk, max_retries=MAX_SOAP_RETRIES)\n",
        "\n",
        "                    if not soap:\n",
        "                        stats[\"soap_fail\"] += 1\n",
        "                        if error_msg:\n",
        "                            stats[\"soap_validation_errors\"][error_msg] = stats[\"soap_validation_errors\"].get(error_msg, 0) + 1\n",
        "                        continue\n",
        "\n",
        "                    if error_msg == \"Partially salvaged\":\n",
        "                        stats[\"soap_retry_success\"] += 1\n",
        "\n",
        "                    # ---- STEP B: SOAP ‚Üí DIALOGUE (with retry) ----\n",
        "                    dialogue, dialogue_error = generate_dialogue_from_soap(soap, max_retries=MAX_DIALOGUE_RETRIES)\n",
        "\n",
        "                    if not dialogue:\n",
        "                        stats[\"dialogue_fail\"] += 1\n",
        "                        if dialogue_error:\n",
        "                            stats[\"dialogue_validation_errors\"][dialogue_error] = stats[\"dialogue_validation_errors\"].get(dialogue_error, 0) + 1\n",
        "                        continue\n",
        "\n",
        "                    if \"retry\" in dialogue_error.lower():\n",
        "                        stats[\"dialogue_retry_success\"] += 1\n",
        "\n",
        "                    # ---- STEP C: FORMAT DATASET ENTRY ----\n",
        "                    target = (\n",
        "                        f\"Subjective: {soap['Subjective']}\\n\"\n",
        "                        f\"Objective: {soap['Objective']}\\n\"\n",
        "                        f\"Assessment: {soap['Assessment']}\\n\"\n",
        "                        f\"Plan: {soap['Plan']}\"\n",
        "                    )\n",
        "\n",
        "                    entry = {\n",
        "                        \"input\": f\"generate soap note:\\n{dialogue}\",\n",
        "                        \"output\": target,\n",
        "                        \"metadata\": {\n",
        "                            \"category\": row[\"CATEGORY\"],\n",
        "                            \"row_id\": int(row[\"ROW_ID\"]) if \"ROW_ID\" in row else None,\n",
        "                            \"note_length\": len(raw_text),\n",
        "                            \"chunk_length\": len(note_chunk),\n",
        "                            \"soap_quality\": \"full\" if error_msg is None else \"partial\",\n",
        "                            \"dialogue_quality\": \"full\" if dialogue_error is None else \"retry_success\",\n",
        "                            \"processing_timestamp\": pd.Timestamp.now().isoformat()\n",
        "                        }\n",
        "                    }\n",
        "\n",
        "                    # Write to file\n",
        "                    fout.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "                    fout.flush()\n",
        "\n",
        "                    stats[\"saved\"] += 1\n",
        "\n",
        "                    # Save checkpoint every 5 samples\n",
        "                    if stats[\"saved\"] % 5 == 0:\n",
        "                        save_checkpoint(stats[\"saved\"])\n",
        "\n",
        "                # Free memory\n",
        "                del df\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n‚ö†Ô∏è Process interrupted by user\")\n",
        "        if stats[\"saved\"] > 0:\n",
        "            save_checkpoint(stats[\"saved\"])\n",
        "            print(f\"üíæ Progress saved: {stats['saved']} samples\")\n",
        "        return stats\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Unexpected error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return stats\n",
        "\n",
        "    print(\"\\n‚úÖ Processing completed!\")\n",
        "    return stats\n",
        "\n",
        "# ==========================================\n",
        "# 7. MAIN EXECUTION\n",
        "# ==========================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üöÄ Starting MIMIC-III to Dialogue-SOAP conversion\")\n",
        "    print(f\"Output file: {OUTPUT_FILE}\")\n",
        "    print(f\"Max samples: {MAX_SAMPLES or 'All'}\")\n",
        "    print(f\"Target categories: {TARGET_CATEGORIES}\")\n",
        "    print(f\"SOAP retries: {MAX_SOAP_RETRIES}\")\n",
        "    print(f\"Dialogue retries: {MAX_DIALOGUE_RETRIES}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    final_stats = process_mimic()\n",
        "\n",
        "    # Clean up checkpoint file if completed\n",
        "    if final_stats and \"saved\" in final_stats:\n",
        "        if MAX_SAMPLES and final_stats[\"saved\"] >= MAX_SAMPLES:\n",
        "            if os.path.exists(CHECKPOINT_FILE):\n",
        "                os.remove(CHECKPOINT_FILE)\n",
        "                print(\"üßπ Checkpoint file removed (completed)\")\n",
        "\n",
        "    # Print statistics\n",
        "    if final_stats:\n",
        "        print(\"\\nüìä FINAL STATISTICS\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"{'Metric':30} {'Count':>10} {'%':>8}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        total = final_stats.get(\"total_processed\", 0)\n",
        "\n",
        "        metrics = [\n",
        "            (\"Total processed\", final_stats.get(\"total_processed\", 0)),\n",
        "            (\"Skipped (short)\", final_stats.get(\"skipped_short\", 0)),\n",
        "            (\"SOAP failed\", final_stats.get(\"soap_fail\", 0)),\n",
        "            (\"SOAP retry success\", final_stats.get(\"soap_retry_success\", 0)),\n",
        "            (\"Dialogue failed\", final_stats.get(\"dialogue_fail\", 0)),\n",
        "            (\"Dialogue retry success\", final_stats.get(\"dialogue_retry_success\", 0)),\n",
        "            (\"Successfully saved\", final_stats.get(\"saved\", 0))\n",
        "        ]\n",
        "\n",
        "        for name, value in metrics:\n",
        "            if total > 0 and name not in [\"Total processed\", \"Successfully saved\"]:\n",
        "                percentage = (value / total) * 100\n",
        "                print(f\"{name:30} {value:10} {percentage:7.1f}%\")\n",
        "            else:\n",
        "                print(f\"{name:30} {value:10}\")\n",
        "\n",
        "        if total > 0:\n",
        "            success_rate = (final_stats.get(\"saved\", 0) / total) * 100\n",
        "            print(\"-\" * 50)\n",
        "            print(f\"{'Success rate':30} {'':10} {success_rate:7.1f}%\")\n",
        "\n",
        "            # Print common validation errors\n",
        "            print(\"\\nüîç TOP VALIDATION ERRORS:\")\n",
        "            soap_errors = final_stats.get(\"soap_validation_errors\", {})\n",
        "            if soap_errors:\n",
        "                print(\"SOAP errors:\")\n",
        "                for error, count in sorted(soap_errors.items(), key=lambda x: x[1], reverse=True)[:3]:\n",
        "                    print(f\"  - {error}: {count}\")\n",
        "\n",
        "            dialogue_errors = final_stats.get(\"dialogue_validation_errors\", {})\n",
        "            if dialogue_errors:\n",
        "                print(\"Dialogue errors:\")\n",
        "                for error, count in sorted(dialogue_errors.items(), key=lambda x: x[1], reverse=True)[:3]:\n",
        "                    print(f\"  - {error}: {count}\")\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    saved = final_stats.get(\"saved\", 0) if final_stats else 0\n",
        "    print(f\"\\n‚è±Ô∏è  Total time: {elapsed:.1f} seconds\")\n",
        "    if saved > 0:\n",
        "        print(f\"   Avg time per sample: {elapsed/saved:.1f}s\")\n",
        "        print(f\"   Samples per hour: {(saved/elapsed)*3600:.1f}\")"
      ]
    }
  ]
}